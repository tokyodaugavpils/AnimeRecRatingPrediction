{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4d43c-ad4e-4f7b-a0ac-923d5d200dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–Ω–∏–º–µ (–∏–ª–∏ '0' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è):  Monster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ –ù–∞–∑–≤–∞–Ω–∏–µ: Monster\n",
      "üìä –†–µ–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥: 8.72\n",
      "ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥: 8.62\n"
     ]
    }
   ],
   "source": [
    "# –®–∞–≥ 0: –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"anime.csv\")\n",
    "\n",
    "# –®–∞–≥ 2: –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∂–∞–Ω—Ä–∞ –∏–ª–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞\n",
    "df = df[df['genre'].notna()]\n",
    "df = df[df['rating'].notna()]\n",
    "\n",
    "# –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –∞–Ω–∏–º–µ (–¥–ª—è –ø–æ–∏—Å–∫–∞)\n",
    "df['name'] = df['name'].astype(str)\n",
    "\n",
    "# –®–∞–≥ 4: –û—Å—Ç–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "df = df[['name', 'genre', 'type', 'episodes', 'members', 'rating']]\n",
    "\n",
    "# –®–∞–≥ 5: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∂–∞–Ω—Ä—ã (genre ‚Äî —Å—Ç—Ä–æ–∫–∞: \"Action, Fantasy\")\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(', '))\n",
    "genre_matrix = vectorizer.fit_transform(df['genre'])\n",
    "\n",
    "# –®–∞–≥ 6: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º \"type\" (TV, Movie –∏ —Ç.–ø.) –≤ —á–∏—Å–ª–∞\n",
    "df['type'] = df['type'].astype('category')\n",
    "df['type_code'] = df['type'].cat.codes\n",
    "\n",
    "# –®–∞–≥ 7: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º episodes (—Å—Ç—Ä–æ–∫–∏ ‚Üí —á–∏—Å–ª–∞ + –∑–∞–º–µ–Ω–∞ NaN –Ω–∞ –º–µ–¥–∏–∞–Ω—É)\n",
    "df['episodes'] = pd.to_numeric(df['episodes'], errors='coerce')\n",
    "df['episodes'] = df['episodes'].fillna(df['episodes'].median())\n",
    "\n",
    "# –®–∞–≥ 8: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (X)\n",
    "X_other = df[['type_code', 'episodes', 'members']].values\n",
    "X_all = np.hstack((genre_matrix.toarray(), X_other))\n",
    "\n",
    "# –®–∞–≥ 9: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (y)\n",
    "y = df['rating'].values\n",
    "\n",
    "# –®–∞–≥ 10: –î–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# –®–∞–≥ 11: –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# –®–∞–≥ 12: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ—à–∏–±–∫–∞\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE):\", round(mse, 2))\n",
    "\n",
    "# –®–∞–≥ 13: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é\n",
    "def predict_anime_rating(anime_name):\n",
    "    results = df[df['name'].str.lower() == anime_name.lower()]\n",
    "\n",
    "    if results.empty:\n",
    "        print(f\"‚ùå –ê–Ω–∏–º–µ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º '{anime_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\")\n",
    "        return\n",
    "\n",
    "    for idx, row in results.iterrows():\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∂–∞–Ω—Ä—ã –≤ –≤–µ–∫—Ç–æ—Ä\n",
    "        genre_vec = vectorizer.transform([row['genre']]).toarray()\n",
    "\n",
    "        # –ü—Ä–∏–∑–Ω–∞–∫–∏: type_code, episodes, members\n",
    "        other_features = np.array([[row['type_code'], row['episodes'], row['members']]])\n",
    "\n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—ë\n",
    "        full_features = np.hstack((genre_vec, other_features))\n",
    "\n",
    "        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "        predicted_rating = model.predict(full_features)[0]\n",
    "\n",
    "        # –†–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        print(f\"\\nüé¨ –ù–∞–∑–≤–∞–Ω–∏–µ: {row['name']}\")\n",
    "        print(f\"üìä –†–µ–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥: {row['rating']}\")\n",
    "        print(f\"ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥: {round(predicted_rating, 2)}\")\n",
    "\n",
    "# –®–∞–≥ 14: –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "while True:\n",
    "    anime_input = input(\"\\n–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–Ω–∏–º–µ (–∏–ª–∏ '0' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è): \")\n",
    "    if anime_input.lower() == '0':\n",
    "        break\n",
    "    predict_anime_rating(anime_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab51fa-ea0a-4275-b0d9-ba4ce7caecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
